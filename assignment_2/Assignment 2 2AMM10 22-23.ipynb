{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d32f8d18",
   "metadata": {},
   "source": [
    "# Group Details\n",
    "\n",
    "## Group Name:\n",
    "\n",
    "### Student 1:\n",
    "\n",
    "### Student 2:\n",
    "\n",
    "### Student 3:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "faec2056",
   "metadata": {},
   "source": [
    "# Loading Data and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0580a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0756591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(filename, task):\n",
    "    datapoint = np.load(filename)\n",
    "    if task == 'task 1':\n",
    "        initial_state = datapoint['initial_state']\n",
    "        terminal_state = datapoint['terminal_state']\n",
    "        return initial_state, terminal_state\n",
    "    elif task == 'task 2' or task == 'task 3':\n",
    "        whole_trajectory = datapoint['trajectory']\n",
    "        # change shape: (num_bodies, attributes, time) ->  num_bodies, time, attributes\n",
    "        whole_trajectory = np.swapaxes(whole_trajectory, 1, 2)\n",
    "        initial_state = whole_trajectory[:, 0]\n",
    "        target = whole_trajectory[:, 1:, 1:]  # drop the first timepoint (second dim) and mass (last dim) for the prediction task\n",
    "        return initial_state, target\n",
    "    else:\n",
    "        raise NotImplementedError(\"'task' argument should be 'task 1', 'task 2' or 'task 3'!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb77a4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of initial state (model input): (8, 5)\n",
      "shape of terminal state (to be predicted by model): (8, 2)\n",
      "The initial x-coordinate of the body with index 4 in this trajectory was -2.7586106638591836\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\"\"\"\n",
    "This cell gives an example of loading a datapoint with numpy for task 1.\n",
    "\n",
    "The arrays returned by the function are structures as follows:\n",
    "initial_state: shape (n_bodies, [mass, x, y, v_x, v_y])\n",
    "terminal_state: shape (n_bodies, [x, y])\n",
    "\n",
    "\"\"\"\n",
    "example = load_array('data/task 1/train/trajectory_0.npz', task='task 1')\n",
    "\n",
    "initial_state, terminal_state = example\n",
    "print(f'shape of initial state (model input): {initial_state.shape}')\n",
    "print(f'shape of terminal state (to be predicted by model): {terminal_state.shape}')\n",
    "\n",
    "body_idx = 4\n",
    "print(f'The initial x-coordinate of the body with index {body_idx} in this trajectory was {initial_state[body_idx, 1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd0bfa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(folder):\n",
    "    file_list = os.listdir(folder)\n",
    "\n",
    "    inputs = []\n",
    "    targets = []\n",
    "\n",
    "    for file_name in file_list:\n",
    "        file_path = os.path.join(folder, file_name)\n",
    "        input, target = load_array(file_path, 'task 1')\n",
    "        inputs.append(torch.from_numpy(input))\n",
    "        targets.append(torch.from_numpy(target))\n",
    "\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc2499e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , y_train = get_data('D:/Master/Y1/Deep learning/Deep-learning/assignment_2/data/task 1/train')\n",
    "X_test, y_test = get_data('D:/Master/Y1/Deep learning/Deep-learning/assignment_2/data/task 1/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23ef8f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "def make_graph(data):\n",
    "       result = []\n",
    "       for i in range(len(data)):\n",
    "              x = data[i]\n",
    "              num_bodies = x.shape[0]\n",
    "              # create a tensor for the edges between nodes\n",
    "              edge_index = torch.tensor([[i, j] for i in range(num_bodies) for j in range(num_bodies) if i != j], dtype=torch.long).t().contiguous()\n",
    "\n",
    "              # create a PyG Data instance for the graph\n",
    "              graph = Data(x=x, edge_index=edge_index)\n",
    "              result.append(graph)\n",
    "       return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f5d90d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_graph = make_graph(X_test)\n",
    "X_train_graph = make_graph(X_train)\n",
    "y_train_graph = make_graph(y_train)\n",
    "y_test_graph = make_graph(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ef69a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_diff = [X_train[i][:, 1:3] - y_train[i] for i in range(len(X_train))]\n",
    "y_test_diff = [X_test[i][:, 1:3] - y_test[i] for i in range(len(X_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "844ae0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_attr(data):\n",
    "    num_bodies = data.shape[0]\n",
    "\n",
    "    # We create a complete graph, so each body is connected to every other body\n",
    "    edge_index = torch.tensor([[i, j] for i in range(num_bodies) for j in range(num_bodies) if i != j]).T\n",
    "\n",
    "    # Calculate the distances and forces for each pair of bodies\n",
    "    differences = data[edge_index[1]] - data[edge_index[0]]\n",
    "    differences = differences[:,1:3]\n",
    "\n",
    "    return differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d41fc786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_edge_attr_y(data):\n",
    "#     num_bodies = data.shape[0]\n",
    "#     edge_index = torch.tensor([[i, j] for i in range(num_bodies) for j in range(num_bodies) if i != j]).T\n",
    "#     differences = data[edge_index[1]] - data[edge_index[0]]\n",
    "#     differences = differences[:,0:2]\n",
    "#     return differences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99d724f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_diff =  [torch.cat((X_train[i][:,:1], X_train[i][:,3:]), dim = 1) for i in range(len(X_train))]\n",
    "X_train_diff_graph = make_graph(X_train_diff)\n",
    "X_test_diff =  [torch.cat((X_test[i][:,:1], X_test[i][:,3:]), dim = 1) for i in range(len(X_test))]\n",
    "X_test_diff_graph = make_graph(X_test_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1874ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = [Data(x=graph.x.to(torch.float32), edge_index=graph.edge_index, edge_attr=get_edge_attr(x).to(torch.float32), y=y.to(torch.float32)) for graph, y, x in zip(X_train_diff_graph, y_train_diff,X_train)]\n",
    "data_test = [Data(x=graph.x.to(torch.float32), edge_index=graph.edge_index, edge_attr=get_edge_attr(x).to(torch.float32), y=y.to(torch.float32)) for graph, y, x in zip(X_test_diff_graph, y_test_diff,X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ca79052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\20172048\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(data_train,batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(data_test, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d53da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.data as pyg_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d09d2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ReadoutLayer(nn.Module):\n",
    "    def __init__(self, edge_feature_dim, output_dim):\n",
    "        super(ReadoutLayer, self).__init__()\n",
    "        self.decoder = nn.Linear(edge_feature_dim, output_dim)\n",
    "\n",
    "    def forward(self, nodes): \n",
    "        # pos_diff = torch.stack([edge_attr[i:i+(nodes.shape[0]-1)].sum(dim=0) for i in range(0, edge_attr.shape[0],nodes.shape[0]-1)]).to(torch.float32)\n",
    "        return nodes[:,1:3]\n",
    "\n",
    "class EdgeUpdateLayer(nn.Module):\n",
    "    def __init__(self, edge_attr_dim):\n",
    "        super(EdgeUpdateLayer, self).__init__()\n",
    "        # self.update_forces = nn.Sequential(\n",
    "        #     nn.Linear(5, 256),\n",
    "        #     nn.Linear(256,1024),\n",
    "        #     nn.Linear(1024,256),\n",
    "        #     nn.Linear(256, 2)\n",
    "        # )\n",
    "\n",
    "\n",
    "    def forward(self, nodes, edge_attr):\n",
    "        # print(nodes[:, :3])\n",
    "        # print(nodes.shape[0])\n",
    "        return get_edge_attr(nodes)\n",
    "        # nodes_exp = nodes.repeat(nodes.shape[0]-1,1)\n",
    "        # # print(nodes_exp.shape[0])\n",
    "    \n",
    "        # return self.update_forces(torch.cat([edge_attr,nodes_exp[:,:3]], dim = 1))\n",
    "\n",
    "class NodeUpdateLayer(nn.Module):\n",
    "    def __init__(self, node_feature_dim, edge_feature_dim):\n",
    "        super(NodeUpdateLayer, self).__init__()\n",
    "        self.update_velocities = nn.Sequential(\n",
    "            nn.Linear(node_feature_dim + edge_feature_dim, 64), # input includes forces\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2) # output dimension is 2 for (velx, vely)\n",
    "        )\n",
    "        self.update_forces = nn.Sequential(\n",
    "            nn.Linear(edge_feature_dim,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "        # self.update_positions = nn.Sequential(\n",
    "        #     nn.Linear(node_feature_dim + 2, 256), # input includes updated velocities\n",
    "        #     nn.Linear(256, 2) # output dimension is 2 for (posx, posy)\n",
    "\n",
    "        # )\n",
    "\n",
    "    def forward(self, nodes, edge_attr):\n",
    "        # print(len(edge_attr))\n",
    "        # updated_forces = torch.stack([edge_attr[i:i+(nodes.shape[0]-1)].sum(dim=0) for i in range(0, edge_attr.shape[0],nodes.shape[0]-1)]).to(torch.float32)\n",
    "        updated_forces = self.update_forces(edge_attr).to(torch.float32)\n",
    "        updated_forces = torch.stack([updated_forces[i:i+(nodes.shape[0]-1)].sum(dim=0) for i in range(0, updated_forces.shape[0],nodes.shape[0]-1)]).to(torch.float32)\n",
    "        # print(nodes)\n",
    "        # print(edge_attr)\n",
    "        # print(updated_forces)\n",
    "        # updated_forces = edge_attr\n",
    "        updated_velocities = self.update_velocities(torch.cat([nodes, updated_forces], dim=1)).to(torch.float32)\n",
    "        # updated_positions = self.update_positions(torch.cat([nodes, updated_velocities], dim=1)).to(torch.float32)\n",
    "        return torch.cat([nodes[:, :1], updated_velocities], dim=1).to(torch.float32) # concatenate mass, and velocities\n",
    "\n",
    "\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, node_feature_dim, edge_feature_dim):\n",
    "        super(GNN, self).__init__()\n",
    "        self.edge_update = EdgeUpdateLayer(edge_feature_dim)\n",
    "        self.node_update = NodeUpdateLayer(node_feature_dim, edge_feature_dim)\n",
    "        self.readout = ReadoutLayer(edge_feature_dim, output_dim=2)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        out = []\n",
    "\n",
    "        # Iterate over all graphs in the batch\n",
    "        for graph in pyg_data.Batch.to_data_list(batch):\n",
    "            nodes = graph.x\n",
    "            edges = graph.edge_index\n",
    "            edge_attr = graph.edge_attr\n",
    "\n",
    "            for T in range(5):  # T is the number of message passing steps\n",
    "                nodes = self.node_update(nodes, edge_attr)\n",
    "                edge_attr = self.edge_update(nodes, edge_attr).to(torch.float32)\n",
    "\n",
    "            out.append(self.readout(nodes))\n",
    "\n",
    "        return torch.cat(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fddbd9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train loss: 12.2017, Test loss: 9.1325\n",
      "Epoch [2/100], Train loss: 11.1122, Test loss: 8.6031\n",
      "Epoch [3/100], Train loss: 10.8818, Test loss: 8.7129\n",
      "Epoch [4/100], Train loss: 11.0104, Test loss: 8.6385\n",
      "Epoch [5/100], Train loss: 10.8339, Test loss: 8.8273\n",
      "Epoch [6/100], Train loss: 10.7307, Test loss: 8.7862\n",
      "Epoch [7/100], Train loss: 10.7113, Test loss: 8.6683\n",
      "Epoch [8/100], Train loss: 10.7988, Test loss: 8.4639\n",
      "Epoch [9/100], Train loss: 10.5073, Test loss: 8.6841\n",
      "Epoch [10/100], Train loss: 10.5700, Test loss: 9.1067\n",
      "Epoch [11/100], Train loss: 10.5003, Test loss: 8.5708\n",
      "Epoch [12/100], Train loss: 10.4137, Test loss: 8.8008\n",
      "Epoch [13/100], Train loss: 10.6063, Test loss: 8.6699\n",
      "Epoch [14/100], Train loss: 10.3604, Test loss: 8.5433\n",
      "Epoch [15/100], Train loss: 10.4583, Test loss: 9.0027\n",
      "Epoch [16/100], Train loss: 10.4310, Test loss: 8.9709\n",
      "Epoch [17/100], Train loss: 10.4360, Test loss: 8.4797\n",
      "Epoch [18/100], Train loss: 10.3727, Test loss: 8.5135\n",
      "Epoch [19/100], Train loss: 10.2671, Test loss: 8.2039\n",
      "Epoch [20/100], Train loss: 10.2400, Test loss: 8.2828\n",
      "Epoch [21/100], Train loss: 10.1669, Test loss: 8.1740\n",
      "Epoch [22/100], Train loss: 10.0616, Test loss: 8.3076\n",
      "Epoch [23/100], Train loss: 10.0853, Test loss: 8.1281\n",
      "Epoch [24/100], Train loss: 9.9776, Test loss: 7.9745\n",
      "Epoch [25/100], Train loss: 9.9437, Test loss: 7.8376\n",
      "Epoch [26/100], Train loss: 9.9555, Test loss: 8.0397\n",
      "Epoch [27/100], Train loss: 9.7293, Test loss: 7.8934\n",
      "Epoch [28/100], Train loss: 9.6195, Test loss: 7.8924\n",
      "Epoch [29/100], Train loss: 9.6339, Test loss: 7.6674\n",
      "Epoch [30/100], Train loss: 9.5130, Test loss: 7.8266\n",
      "Epoch [31/100], Train loss: 9.3982, Test loss: 7.4779\n",
      "Epoch [32/100], Train loss: 9.2079, Test loss: 6.8024\n",
      "Epoch [33/100], Train loss: 8.5566, Test loss: 6.2953\n",
      "Epoch [34/100], Train loss: 8.1928, Test loss: 5.7067\n",
      "Epoch [35/100], Train loss: 7.9813, Test loss: 6.0439\n",
      "Epoch [36/100], Train loss: 7.9420, Test loss: 5.8724\n",
      "Epoch [37/100], Train loss: 7.8012, Test loss: 5.7545\n",
      "Epoch [38/100], Train loss: 7.7358, Test loss: 5.4029\n",
      "Epoch [39/100], Train loss: 7.7296, Test loss: 5.6140\n",
      "Epoch [40/100], Train loss: 7.6626, Test loss: 5.4972\n",
      "Epoch [41/100], Train loss: 7.5742, Test loss: 5.2753\n",
      "Epoch [42/100], Train loss: 7.7090, Test loss: 5.0922\n",
      "Epoch [43/100], Train loss: 7.3652, Test loss: 5.2497\n",
      "Epoch [44/100], Train loss: 7.3753, Test loss: 4.9557\n",
      "Epoch [45/100], Train loss: 7.3562, Test loss: 5.3351\n",
      "Epoch [46/100], Train loss: 7.3803, Test loss: 4.9742\n",
      "Epoch [47/100], Train loss: 7.2973, Test loss: 5.0174\n",
      "Epoch [48/100], Train loss: 7.1137, Test loss: 5.0870\n",
      "Epoch [49/100], Train loss: 7.1871, Test loss: 4.9801\n",
      "Epoch [50/100], Train loss: 7.0786, Test loss: 5.0473\n",
      "Epoch [51/100], Train loss: 7.0412, Test loss: 5.0194\n",
      "Epoch [52/100], Train loss: 6.9581, Test loss: 5.0405\n",
      "Epoch [53/100], Train loss: 6.9168, Test loss: 4.9069\n",
      "Epoch [54/100], Train loss: 6.9591, Test loss: 4.8353\n",
      "Epoch [55/100], Train loss: 6.9904, Test loss: 4.6172\n",
      "Epoch [56/100], Train loss: 6.8499, Test loss: 4.9025\n",
      "Epoch [57/100], Train loss: 6.8888, Test loss: 4.9291\n",
      "Epoch [58/100], Train loss: 6.7668, Test loss: 4.9321\n",
      "Epoch [59/100], Train loss: 6.7509, Test loss: 5.0839\n",
      "Epoch [60/100], Train loss: 6.7951, Test loss: 4.5797\n",
      "Epoch [61/100], Train loss: 6.7994, Test loss: 5.0552\n",
      "Epoch [62/100], Train loss: 6.7507, Test loss: 4.9472\n",
      "Epoch [63/100], Train loss: 6.8307, Test loss: 4.6890\n",
      "Epoch [64/100], Train loss: 6.7463, Test loss: 4.5762\n",
      "Epoch [65/100], Train loss: 6.6351, Test loss: 4.4565\n",
      "Epoch [66/100], Train loss: 6.6745, Test loss: 4.6447\n",
      "Epoch [67/100], Train loss: 6.6679, Test loss: 4.5729\n",
      "Epoch [68/100], Train loss: 6.7602, Test loss: 4.6198\n",
      "Epoch [69/100], Train loss: 6.5922, Test loss: 4.5034\n",
      "Epoch [70/100], Train loss: 6.5401, Test loss: 4.5089\n",
      "Epoch [71/100], Train loss: 6.5048, Test loss: 4.5401\n",
      "Epoch [72/100], Train loss: 6.5809, Test loss: 4.7553\n",
      "Epoch [73/100], Train loss: 6.4982, Test loss: 4.7025\n",
      "Epoch [74/100], Train loss: 6.5694, Test loss: 4.5688\n",
      "Epoch [75/100], Train loss: 6.4760, Test loss: 4.6852\n",
      "Epoch [76/100], Train loss: 6.4427, Test loss: 4.3778\n",
      "Epoch [77/100], Train loss: 6.3871, Test loss: 4.6874\n",
      "Epoch [78/100], Train loss: 6.3545, Test loss: 4.3484\n",
      "Epoch [79/100], Train loss: 6.4292, Test loss: 4.3793\n",
      "Epoch [80/100], Train loss: 6.3983, Test loss: 4.5496\n",
      "Epoch [81/100], Train loss: 6.4197, Test loss: 4.4496\n",
      "Epoch [82/100], Train loss: 6.3302, Test loss: 4.4950\n",
      "Epoch [83/100], Train loss: 6.3625, Test loss: 4.4646\n",
      "Epoch [84/100], Train loss: 6.4300, Test loss: 4.2073\n",
      "Epoch [85/100], Train loss: 6.2901, Test loss: 4.5662\n",
      "Epoch [86/100], Train loss: 6.2802, Test loss: 4.0868\n",
      "Epoch [87/100], Train loss: 6.3262, Test loss: 4.3609\n",
      "Epoch [88/100], Train loss: 6.2307, Test loss: 4.2833\n",
      "Epoch [89/100], Train loss: 6.3145, Test loss: 4.8082\n",
      "Epoch [90/100], Train loss: 6.2289, Test loss: 4.3780\n",
      "Epoch [91/100], Train loss: 6.3255, Test loss: 4.0011\n",
      "Epoch [92/100], Train loss: 6.3169, Test loss: 4.7574\n",
      "Epoch [93/100], Train loss: 6.2189, Test loss: 4.3080\n",
      "Epoch [94/100], Train loss: 6.1918, Test loss: 4.2803\n",
      "Epoch [95/100], Train loss: 6.1653, Test loss: 4.1200\n",
      "Epoch [96/100], Train loss: 6.2403, Test loss: 4.4339\n",
      "Epoch [97/100], Train loss: 6.2252, Test loss: 4.6176\n",
      "Epoch [98/100], Train loss: 6.1655, Test loss: 4.4741\n",
      "Epoch [99/100], Train loss: 6.1797, Test loss: 4.2326\n",
      "Epoch [100/100], Train loss: 6.1757, Test loss: 4.2243\n"
     ]
    }
   ],
   "source": [
    "# Loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "model_task1 = GNN(3,2)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model_task1.parameters())\n",
    "\n",
    "# Number of epochs\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_task1.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        targets_batch = batch.y\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_task1(batch)\n",
    "        loss = criterion(outputs, targets_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    total_loss /= len(train_loader)\n",
    "\n",
    "    model_task1.eval()\n",
    "\n",
    "    total_test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            targets_batch = batch.y\n",
    "            outputs = model_task1(batch)\n",
    "            loss_test = criterion(outputs, targets_batch)\n",
    "            total_test_loss += loss_test.item()\n",
    "\n",
    "    total_test_loss /= len(test_loader)\n",
    "\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        print ('Epoch [{}/{}], Train loss: {:.4f}, Test loss: {:.4f}'.format(epoch+1, epochs, total_loss, total_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c3ea4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of initial state (model input): (8, 5)\n",
      "shape of terminal state (to be predicted by model): (8, 49, 4)\n",
      "The y-coordinate of the body with index 2 at time with index 30 in remaining_trajectory was -0.3861544940435097\n",
      "the shape of the input of a test data example is (8, 5)\n",
      "the shape of the target of a test data example is (8, 49, 4)\n",
      "values of the test data example at time 30:\n",
      " [[-1.11611543  3.21149953         nan         nan]\n",
      " [-0.2865083   4.30801877         nan         nan]\n",
      " [ 1.07701594 -8.12529269         nan         nan]\n",
      " [-0.92053478  3.13709551         nan         nan]\n",
      " [-3.96308297 -4.27733589         nan         nan]\n",
      " [ 2.33945401 -8.67733599         nan         nan]\n",
      " [-4.83949085  3.67854952         nan         nan]\n",
      " [ 0.31080159 -9.74720071         nan         nan]]\n",
      "note: velocity values are unobserved (NaNs) in the test data!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell gives an example of loading a datapoint with numpy for task 2 / 3.\n",
    "\n",
    "The arrays returned by the function are structures as follows:\n",
    "initial_state: shape (n_bodies, [mass, x, y, v_x, v_y])\n",
    "remaining_trajectory: shape (n_bodies, time, [x, y, v_x, v_y])\n",
    "\n",
    "Note that for this task, you are asked to evaluate performance only with regard to the predictions of the positions (x and y).\n",
    "If you use the velocity of the remaining trajectory for training,\n",
    "this use should be purely auxiliary for the goal of predicting the positions [x,y] over time. \n",
    "While testing performance of your model on the test set, you do not have access to v_x and v_y of the remaining trajectory.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "example = load_array('data/task 2_3/train/trajectory_0.npz', task='task 2')\n",
    "\n",
    "initial_state, remaining_trajectory = example\n",
    "print(f'shape of initial state (model input): {initial_state.shape}')\n",
    "print(f'shape of terminal state (to be predicted by model): {remaining_trajectory.shape}')\n",
    "\n",
    "body_idx = 2\n",
    "time_idx = 30\n",
    "print(f'The y-coordinate of the body with index {body_idx} at time with index {time_idx} in remaining_trajectory was {remaining_trajectory[body_idx, time_idx, 1]}')\n",
    "\n",
    "test_example = load_array('data/task 2_3/test/trajectory_900.npz', task='task 3')\n",
    "test_initial_state, test_remaining_trajectory = test_example\n",
    "print(f'the shape of the input of a test data example is {test_initial_state.shape}')\n",
    "print(f'the shape of the target of a test data example is {test_remaining_trajectory.shape}')\n",
    "print(f'values of the test data example at time {time_idx}:\\n {test_remaining_trajectory[:, time_idx]}')\n",
    "print('note: velocity values are unobserved (NaNs) in the test data!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28681a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "059b633c",
   "metadata": {},
   "source": [
    "# Data Handling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6ecb529",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8633eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a99a32b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18b2874d",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66774050",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba598378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95154df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dea70d73",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3af520ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95af5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e03ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5fb3b29",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf5fa1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280031f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8240f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
